{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reflected-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imposed-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect every year's speech data and party affiliation data \n",
    "for year in range(2015, 2022):\n",
    "    speech = [] # a list to collect speech data\n",
    "    party = [] # a list to collect party affiliation data\n",
    "    file_names = pd.read_csv(str(year)+\"_fnames.txt\", header=None) # read the file name lists of the year\n",
    "    for f in file_names[0]:\n",
    "        if '.txt' in f: # txt file contains the speech data\n",
    "            text_data = pd.read_csv(str(year)+\"/\"+f, sep='\\t', header=None)\n",
    "            speech.append(text_data.iloc[:,[1]])\n",
    "        else: # tsv file contains the party affiliation data\n",
    "            label_data = pd.read_csv(str(year)+\"/\"+f, sep='\\t')\n",
    "            party.append(label_data[['Speaker_party']])\n",
    "            \n",
    "    if year == 2015:\n",
    "        speech_party_2015 = pd.concat([speech[0],party[0]],axis=1) \n",
    "        for i in range(1,len(speech)):\n",
    "            sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "            speech_party_2015 = pd.concat([speech_party_2015, sp], ignore_index=True)\n",
    "    elif year == 2016:        \n",
    "        speech_party_2016 = pd.concat([speech[0],party[0]],axis=1)\n",
    "        for i in range(1,len(speech)):\n",
    "            sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "            speech_party_2016 = pd.concat([speech_party_2016, sp], ignore_index=True)\n",
    "    elif year == 2017:        \n",
    "        speech_party_2017 = pd.concat([speech[0],party[0]],axis=1)\n",
    "        for i in range(1,len(speech)):\n",
    "            sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "            speech_party_2017 = pd.concat([speech_party_2017, sp], ignore_index=True)\n",
    "    elif year == 2018:        \n",
    "        speech_party_2018 = pd.concat([speech[0],party[0]],axis=1)\n",
    "        for i in range(1,len(speech)):\n",
    "            sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "            speech_party_2018 = pd.concat([speech_party_2018, sp], ignore_index=True)\n",
    "    elif year == 2019:        \n",
    "        speech_party_2019 = pd.concat([speech[0],party[0]],axis=1)\n",
    "        for i in range(1,len(speech)):\n",
    "            sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "            speech_party_2019 = pd.concat([speech_party_2019, sp], ignore_index=True)\n",
    "    elif year == 2020:        \n",
    "        speech_party_2020 = pd.concat([speech[0],party[0]],axis=1)\n",
    "        for i in range(1,len(speech)):\n",
    "            sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "            speech_party_2020 = pd.concat([speech_party_2020, sp], ignore_index=True)\n",
    "    elif year == 2021:        \n",
    "        speech_party_2021 = pd.concat([speech[0],party[0]],axis=1)\n",
    "        for i in range(1,len(speech)):\n",
    "            sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "            speech_party_2021 = pd.concat([speech_party_2021, sp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "innocent-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all of the year data in one data frame\n",
    "df_list = [speech_party_2015, speech_party_2016, speech_party_2017, speech_party_2018, speech_party_2019, speech_party_2020, speech_party_2021]\n",
    "speech_party = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "figured-panic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550489"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the total number of dataset\n",
    "speech_party['Speaker_party'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "friendly-attack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CON            321842\n",
       "LAB            133548\n",
       "LD              30220\n",
       "SNP             27004\n",
       "CB              15646\n",
       "DUP              6382\n",
       "I                2531\n",
       "PC               2415\n",
       "-                2393\n",
       "BI               1771\n",
       "GP               1766\n",
       "CON;I             824\n",
       "SDLP              813\n",
       "UUP               710\n",
       "LAB;NA            573\n",
       "UKIP              490\n",
       "CON;NA            225\n",
       "IL                158\n",
       "IGC               155\n",
       "CB;NA             139\n",
       "A                 129\n",
       "LI                 96\n",
       "IGC;LJ95           90\n",
       "PC;I               88\n",
       "LD;NA              73\n",
       "I;LD               70\n",
       "QMZZ               53\n",
       "L8TA               49\n",
       "NA;LAB             44\n",
       "CON;CB             31\n",
       "LD;CB              24\n",
       "I;CON              23\n",
       "ZKPW               21\n",
       "64RT               18\n",
       "SNP;I              18\n",
       "LAB;I              16\n",
       "CON;I;LD            9\n",
       "UKIP;NA             8\n",
       "NA;LD               7\n",
       "NA;CB               7\n",
       "CON;LD              3\n",
       "UKIP;I              2\n",
       "CON;0UBS;NA         2\n",
       "LD;NA;CB            1\n",
       "I;LAB               1\n",
       "CON;NA;CB           1\n",
       "Name: Speaker_party, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count values\n",
    "speech_party['Speaker_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacterial-command",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CON    1000\n",
       "LAB    1000\n",
       "Name: Speaker_party, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect the speech and party affiliation data of 2015 with downsized samples of 1000\n",
    "speech = [] # a list to collect speech data\n",
    "party = [] # a list to collect party affiliation data\n",
    "file_names = pd.read_csv(\"2015_fnames.txt\", header=None) # read the file name lists of the year 2015\n",
    "for f in file_names[0]:\n",
    "    if '.txt' in f: # txt file contains the speech data\n",
    "        text_data = pd.read_csv(\"2015/\"+f, sep='\\t', header=None)\n",
    "        speech.append(text_data.iloc[:,[1]])\n",
    "    else: # tsv file contains the party affiliation data\n",
    "        label_data = pd.read_csv(\"2015/\"+f, sep='\\t')\n",
    "        party.append(label_data[['Speaker_party']])\n",
    "        \n",
    "speech_party = pd.concat([speech[0],party[0]],axis=1) \n",
    "for i in range(1,len(speech)):\n",
    "    sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "    speech_party = pd.concat([speech_party, sp], ignore_index=True)\n",
    "# speech_party['Speaker_party'].value_counts()\n",
    "df_CON = speech_party[speech_party['Speaker_party']=='CON'] # right party\n",
    "df_LAB = speech_party[speech_party['Speaker_party']=='LAB'] # left party\n",
    "            \n",
    "df_CON_downsampled = df_CON.sample(1000) # downsample to 1000 \n",
    "df_LAB_downsampled = df_LAB.sample(1000) # downsample to 1000\n",
    "            \n",
    "df_balanced_2015 = pd.concat([df_CON_downsampled,df_LAB_downsampled]) # downsampled speech data of 2015\n",
    "df_balanced_2015['Speaker_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "matched-chaos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CON    1000\n",
       "LAB    1000\n",
       "Name: Speaker_party, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect the speech and party affiliation data of 2016 with downsized samples of 1000\n",
    "speech = [] # a list to collect speech data\n",
    "party = [] # a list to collect party affiliation data\n",
    "file_names = pd.read_csv(\"2016_fnames.txt\", header=None) # read the file name lists of the year 2016\n",
    "for f in file_names[0]:\n",
    "    if '.txt' in f: # txt file contains the speech data\n",
    "        text_data = pd.read_csv(\"2016/\"+f, sep='\\t', header=None)\n",
    "        speech.append(text_data.iloc[:,[1]])\n",
    "    else: # tsv file contains the party affiliation data\n",
    "        label_data = pd.read_csv(\"2016/\"+f, sep='\\t')\n",
    "        party.append(label_data[['Speaker_party']])\n",
    "        \n",
    "speech_party = pd.concat([speech[0],party[0]],axis=1) \n",
    "for i in range(1,len(speech)):\n",
    "    sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "    speech_party = pd.concat([speech_party, sp], ignore_index=True)\n",
    "# speech_party['Speaker_party'].value_counts()\n",
    "df_CON = speech_party[speech_party['Speaker_party']=='CON'] # right party\n",
    "df_LAB = speech_party[speech_party['Speaker_party']=='LAB'] # left party\n",
    "            \n",
    "df_CON_downsampled = df_CON.sample(1000) # downsample to 1000 \n",
    "df_LAB_downsampled = df_LAB.sample(1000) # downsample to 1000\n",
    "            \n",
    "df_balanced_2016 = pd.concat([df_CON_downsampled,df_LAB_downsampled]) # downsampled speech data of 2016\n",
    "df_balanced_2016['Speaker_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "racial-switzerland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CON    1000\n",
       "LAB    1000\n",
       "Name: Speaker_party, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect the speech and party affiliation data of 2017 with downsized samples of 1000\n",
    "speech = [] # a list to collect speech data\n",
    "party = [] # a list to collect party affiliation data\n",
    "file_names = pd.read_csv(\"2017_fnames.txt\", header=None) # read the file name lists of the year\n",
    "for f in file_names[0]:\n",
    "    if '.txt' in f: # txt file contains the speech data\n",
    "        text_data = pd.read_csv(\"2017/\"+f, sep='\\t', header=None)\n",
    "        speech.append(text_data.iloc[:,[1]])\n",
    "    else: # tsv file contains the party affiliation data\n",
    "        label_data = pd.read_csv(\"2017/\"+f, sep='\\t')\n",
    "        party.append(label_data[['Speaker_party']])\n",
    "        \n",
    "speech_party = pd.concat([speech[0],party[0]],axis=1) \n",
    "for i in range(1,len(speech)):\n",
    "    sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "    speech_party = pd.concat([speech_party, sp], ignore_index=True)\n",
    "# speech_party['Speaker_party'].value_counts()\n",
    "df_CON = speech_party[speech_party['Speaker_party']=='CON'] # right party\n",
    "df_LAB = speech_party[speech_party['Speaker_party']=='LAB'] # left party\n",
    "            \n",
    "df_CON_downsampled = df_CON.sample(1000) # downsample to 1000 \n",
    "df_LAB_downsampled = df_LAB.sample(1000) # downsample to 1000\n",
    "            \n",
    "df_balanced_2017 = pd.concat([df_CON_downsampled,df_LAB_downsampled]) # downsampled speech data of 2017\n",
    "df_balanced_2017['Speaker_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eligible-fault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CON    1000\n",
       "LAB    1000\n",
       "Name: Speaker_party, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect the speech and party affiliation data of 2018 with downsized samples of 1000\n",
    "speech = [] # a list to collect speech data\n",
    "party = [] # a list to collect party affiliation data\n",
    "file_names = pd.read_csv(\"2018_fnames.txt\", header=None) # read the file name lists of the year, 2018\n",
    "for f in file_names[0]:\n",
    "    if '.txt' in f: # txt file contains the speech data\n",
    "        text_data = pd.read_csv(\"2018/\"+f, sep='\\t', header=None)\n",
    "        speech.append(text_data.iloc[:,[1]])\n",
    "    else: # tsv file contains the party affiliation data\n",
    "        label_data = pd.read_csv(\"2018/\"+f, sep='\\t')\n",
    "        party.append(label_data[['Speaker_party']])\n",
    "        \n",
    "speech_party = pd.concat([speech[0],party[0]],axis=1) \n",
    "for i in range(1,len(speech)):\n",
    "    sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "    speech_party = pd.concat([speech_party, sp], ignore_index=True)\n",
    "# speech_party['Speaker_party'].value_counts()\n",
    "df_CON = speech_party[speech_party['Speaker_party']=='CON'] # right party\n",
    "df_LAB = speech_party[speech_party['Speaker_party']=='LAB'] # left party\n",
    "            \n",
    "df_CON_downsampled = df_CON.sample(1000) # downsample to 1000 \n",
    "df_LAB_downsampled = df_LAB.sample(1000) # downsample to 1000\n",
    "            \n",
    "df_balanced_2018 = pd.concat([df_CON_downsampled,df_LAB_downsampled]) # downsampled speech data of 2018\n",
    "df_balanced_2018['Speaker_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cubic-coordinate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CON    1000\n",
       "LAB    1000\n",
       "Name: Speaker_party, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect the speech and party affiliation data of 2019 with downsized samples of 1000\n",
    "speech = [] # a list to collect speech data\n",
    "party = [] # a list to collect party affiliation data\n",
    "file_names = pd.read_csv(\"2019_fnames.txt\", header=None) # read the file name lists of the year, 2019\n",
    "for f in file_names[0]:\n",
    "    if '.txt' in f: # txt file contains the speech data\n",
    "        text_data = pd.read_csv(\"2019/\"+f, sep='\\t', header=None)\n",
    "        speech.append(text_data.iloc[:,[1]])\n",
    "    else: # tsv file contains the party affiliation data\n",
    "        label_data = pd.read_csv(\"2019/\"+f, sep='\\t')\n",
    "        party.append(label_data[['Speaker_party']])\n",
    "        \n",
    "speech_party = pd.concat([speech[0],party[0]],axis=1) \n",
    "for i in range(1,len(speech)):\n",
    "    sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "    speech_party = pd.concat([speech_party, sp], ignore_index=True)\n",
    "# speech_party['Speaker_party'].value_counts()\n",
    "df_CON = speech_party[speech_party['Speaker_party']=='CON'] # right party\n",
    "df_LAB = speech_party[speech_party['Speaker_party']=='LAB'] # left party\n",
    "            \n",
    "df_CON_downsampled = df_CON.sample(1000) # downsample to 1000 \n",
    "df_LAB_downsampled = df_LAB.sample(1000) # downsample to 1000\n",
    "            \n",
    "df_balanced_2019 = pd.concat([df_CON_downsampled,df_LAB_downsampled]) # downsampled speech data of 2019\n",
    "df_balanced_2019['Speaker_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "resistant-reduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CON    1000\n",
       "LAB    1000\n",
       "Name: Speaker_party, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect the speech and party affiliation data of 2020 with downsized samples of 1000\n",
    "speech = [] # a list to collect speech data\n",
    "party = [] # a list to collect party affiliation data\n",
    "file_names = pd.read_csv(\"2020_fnames.txt\", header=None) # read the file name lists of the year, 2020\n",
    "for f in file_names[0]:\n",
    "    if '.txt' in f: # txt file contains the speech data\n",
    "        text_data = pd.read_csv(\"2020/\"+f, sep='\\t', header=None)\n",
    "        speech.append(text_data.iloc[:,[1]])\n",
    "    else: # tsv file contains the party affiliation data\n",
    "        label_data = pd.read_csv(\"2020/\"+f, sep='\\t')\n",
    "        party.append(label_data[['Speaker_party']])\n",
    "        \n",
    "speech_party = pd.concat([speech[0],party[0]],axis=1) \n",
    "for i in range(1,len(speech)):\n",
    "    sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "    speech_party = pd.concat([speech_party, sp], ignore_index=True)\n",
    "# speech_party['Speaker_party'].value_counts()\n",
    "df_CON = speech_party[speech_party['Speaker_party']=='CON'] # right party\n",
    "df_LAB = speech_party[speech_party['Speaker_party']=='LAB'] # left party\n",
    "            \n",
    "df_CON_downsampled = df_CON.sample(1000) # downsample to 1000 \n",
    "df_LAB_downsampled = df_LAB.sample(1000) # downsample to 1000\n",
    "            \n",
    "df_balanced_2020 = pd.concat([df_CON_downsampled,df_LAB_downsampled]) # downsampled speech data of 2020\n",
    "df_balanced_2020['Speaker_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rolled-think",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CON    1000\n",
       "LAB    1000\n",
       "Name: Speaker_party, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect the speech and party affiliation data of 2021 with downsized samples of 1000\n",
    "speech = [] # a list to collect speech data\n",
    "party = [] # a list to collect party affiliation data\n",
    "file_names = pd.read_csv(\"2021_fnames.txt\", header=None) # read the file name lists of the year, 2021\n",
    "for f in file_names[0]:\n",
    "    if '.txt' in f: # txt file contains the speech data\n",
    "        text_data = pd.read_csv(\"2021/\"+f, sep='\\t', header=None)\n",
    "        speech.append(text_data.iloc[:,[1]])\n",
    "    else: # tsv file contains the party affiliation data\n",
    "        label_data = pd.read_csv(\"2021/\"+f, sep='\\t')\n",
    "        party.append(label_data[['Speaker_party']])\n",
    "        \n",
    "speech_party = pd.concat([speech[0],party[0]],axis=1) \n",
    "for i in range(1,len(speech)):\n",
    "    sp = pd.concat([speech[i],party[i]],axis=1)\n",
    "    speech_party = pd.concat([speech_party, sp], ignore_index=True)\n",
    "# speech_party['Speaker_party'].value_counts()\n",
    "df_CON = speech_party[speech_party['Speaker_party']=='CON'] # right party\n",
    "df_LAB = speech_party[speech_party['Speaker_party']=='LAB'] # left party\n",
    "            \n",
    "df_CON_downsampled = df_CON.sample(1000) # downsample to 1000 \n",
    "df_LAB_downsampled = df_LAB.sample(1000) # downsample to 1000\n",
    "            \n",
    "df_balanced_2021 = pd.concat([df_CON_downsampled,df_LAB_downsampled]) # downsampled speech data of 2021\n",
    "df_balanced_2021['Speaker_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "frequent-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all of the year data in one data frame\n",
    "df_list = [df_balanced_2015, df_balanced_2016, df_balanced_2017, df_balanced_2018, df_balanced_2019, df_balanced_2020, df_balanced_2021]\n",
    "speech_party = pd.concat(df_list, ignore_index=True)\n",
    "speech_party.rename(columns={1:'Speech'}, inplace=True) # change the name of column which contains speech data as 'Speech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "strange-sample",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speech</th>\n",
       "      <th>Speaker_party</th>\n",
       "      <th>CON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What does the Secretary of State believe the n...</td>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given the importance of value for money, does ...</td>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My Lords, with Amendment 33Y, we come to the i...</td>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I give my hon. Friend an absolute assurance. O...</td>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I will conclude by saying that some remarkable...</td>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>As we know, we are now a year into this pandem...</td>\n",
       "      <td>LAB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>May I first declare that I am a member of Unit...</td>\n",
       "      <td>LAB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>My Lords, many experts conclude that without n...</td>\n",
       "      <td>LAB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>One of my constituents is a long-term in-patie...</td>\n",
       "      <td>LAB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>Did the Secretary of State know, when the Prim...</td>\n",
       "      <td>LAB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Speech Speaker_party  CON\n",
       "0      What does the Secretary of State believe the n...           CON    1\n",
       "1      Given the importance of value for money, does ...           CON    1\n",
       "2      My Lords, with Amendment 33Y, we come to the i...           CON    1\n",
       "3      I give my hon. Friend an absolute assurance. O...           CON    1\n",
       "4      I will conclude by saying that some remarkable...           CON    1\n",
       "...                                                  ...           ...  ...\n",
       "13995  As we know, we are now a year into this pandem...           LAB    0\n",
       "13996  May I first declare that I am a member of Unit...           LAB    0\n",
       "13997  My Lords, many experts conclude that without n...           LAB    0\n",
       "13998  One of my constituents is a long-term in-patie...           LAB    0\n",
       "13999  Did the Secretary of State know, when the Prim...           LAB    0\n",
       "\n",
       "[14000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label our dataset into 1 and 0\n",
    "# if it is right party, label would be 1 and if it is left party, label would be 0\n",
    "speech_party['CON']=speech_party['Speaker_party'].apply(lambda x: 1 if x=='CON' else 0) \n",
    "speech_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ongoing-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset using the train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = speech_party.Speech.values\n",
    "y = speech_party.CON.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=speech_party['CON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "possible-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# word vectorization using TF-IDF so that speech data(text data) can be used in SVM classifier\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(speech_party['Speech'])\n",
    "X_train_Tfidf = Tfidf_vect.transform(X_train)\n",
    "X_test_Tfidf = Tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "leading-tooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1750\n",
      "           1       0.76      0.74      0.75      1750\n",
      "\n",
      "    accuracy                           0.75      3500\n",
      "   macro avg       0.75      0.75      0.75      3500\n",
      "weighted avg       0.75      0.75      0.75      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# fit the training dataset on the SVM classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train_Tfidf,y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test_Tfidf)\n",
    "\n",
    "# classification report of the current NB classifier\n",
    "print(classification_report(y_test, predictions_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-history",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
